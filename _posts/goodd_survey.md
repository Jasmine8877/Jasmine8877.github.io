
------
图OOD检测方面
1. 强调节点分类的主要目的是将节点归入预定义类别，而OOD检测更像是一个附加功能。​​OOD检测只是一个filter,把ood节点过滤掉就行，质疑是否有研究专门以OOD检测为主要目的​​？还是主要进行节点分类，OOD只是怕影响分类效果？
如果模型在一个闭集场景中将节点 A 错分成 B，这只是分类精度的损失。

目标角度：纯粹的 OOD 检测研究目标就是学习一个最优化 ID 分布边界的模型，它们甚至可以不进行任何 ID 节点分类，对 OOD 样本的检测能力就是其唯一目标。它的价值不在于提升 GNN 的分类准确率，而在于**提升系统识别未知风险的能力**。
评价指标角度：评估 OODD 的指标（AUROC、FPR@95%TPR）与分类指标（Accuracy、F1-Score）是完全独立的。一个分类精度很高的模型，其 OODD 性能可能极差。这强调了 OODD 作为一个独立任务的地位。

后续研究不是以“检测 OOD 为最终目标”，而是为了更好的分类、识别或增量学习服务。

1. OODD单独作为任务处理需先筛除分布外节点再进行分类​​，否则缺乏意义。   
分类: 解决的是识别问题Identification，目标是学习一个映射 $f: \mathcal{X} \to \{c_1, c_2, \dots, c_C\}$，将输入样本映射到 $C$ 个已知的离散标签空间内。
OOD检测: 解决的是判别问题Discrimination，目标是学习一个二元判别函数 $g: \mathcal{X} \to \{\text{ID}, \text{OOD}\}$，判断输入样本是否属于训练时见过的数据生成分布。

1. 既然是OOD检测，为什么还要训练ID分类器？
如果能把ID分类好，反向也就能把OOD识别出来。
OODD 独立于分类任务，但依赖于分类器的特征学习能力。目标是判别样本是否来自OOD。主流方法通过训练 ID 分类器，并从其输出中计算 OOD 分数，分类器训练是 OOD 检测的必要基石。

1. 追问研究现状，为什么追问研究现状？
强调研究现状的重要性，​​指出若已有更优方案则当前工作价值会降低​​。
1. OOD检测的出发点是什么，为什么要OOD检测？
OOD节点会把ID节点平均掉影响ID分类效果，所以要检测OOD。x
为了提升系统识别未知风险的能力。反映在实际应用上，比如单位的人脸识别系统，如果有陌生人企图非法闯入，如果系统没有分布外检测能力，会把该陌生人强行与已知人脸匹配，造成安全问题。
反驳：其实可以设定阈值，如果匹配的最大logits概率大于α，才算匹配成功。
答：上述就是用于OOD检测的MSP方法的核心思想。

1. 如何证明OODD是一个独立的研究任务，而不是分类任务的附属品？
目标是识别那些模型从未在训练中见过、无法可靠预测的样本，并**避免模型在未知样本上做出自信但错误的决策**。它解决的是 模型可靠性问题，不是提高ID分类准确率。
MSP证明模型会以极高置信度给一个完全陌生的样本做出错误预测，在MNIST训练的分类器，给一张人脸测试，模型结果可能是：“这是数字 8，置信度 0.999”。

---
[Revisiting Score Propagation in Graph Out-of-Distribution Detection]
1. 如果可以预言测试集中的特定子集只属于ID或OOD，则可以通过添加内边或移除间边来扩充图(❌️都知道属于啥了，还检测什么)。因此，这将改善内边的比率η intra，导致增强的传播后的OOD检测性能。显然无法预言，可使用分配给节点的伪标签，但存在确认偏差。为了规避它，提出了将边添加到训练集Vl的子集的解决方案，该子集被保证是分布内数据。把增加的ID边(将边缘添加到训练数据的子集G，然后使用增强的邻接矩阵传播分布外（OOD）评分向量)添加到训练集对测试OOD有什么作用？
2. 在测试时影响，模型已经训练好了再去施加新边有啥用？
这些新边不是用来训练模型参数的，它们是用来修正和传播模型已经输出的“OOD 分数”的。新边是为了优化分数传播的路径，而不是优化 GNN 的权重 $\mathbf{W}$。
1. 知道ID即隐含知道OOD，模型到底是怎么训练的，新增边怎么有助于OOD检测？   
模型训练好只是完成了第一步：生成一个有缺陷的初始OOD分数 $\mathbf{\hat{g}}$。施加新边是为了完成第二步：修正 $\mathbf{\hat{g}}$，确保它能够准确反映 ID/OOD 节点的真实状态，这是图 OOD 检测特有的关键步骤。
新增边是 $\text{OOD}$ 检测的一次性后处理工具。它没有改变模型对特征的理解，但它修复了图结构对分数传播的破坏，从而保证了 $\text{OOD}$ 检测这个独立任务的最终性能。
通过增加 $\text{ID}$ 边，GRASP 并没有消除 OOD 污染，而是改变了节点听取邻居意见的权重，听取的ID节点的意见越多，越靠近ID区域。
1. 训练集是有邻接矩阵的图结构吗，还是单个节点？
图结构。
1. 测试时是一个一个节点测试吗？测试集是有邻接矩阵的图结构吗？需要连接上训练图的节点吗？
在测试阶段，训练好的基础 GNN 模型 $F$ 会对整个图 $\mathcal{G}$ 上的所有节点进行一次前向传播，得到所有节点的初始 OOD 分数。
测试集节点必须连接在训练图上。如果测试集节点是孤立的，那就退化成了传统的（非图结构的）OOD 检测任务，图结构带来的挑战和优势（包括 GRASP 的价值）将不复存在。

---------
1.  传统图像的分布外检测的核心任务？
假设模型在训练时只见过 $C$ 个类别（ID），在推理时，它需要判断新输入的样本是否来自这 $C$ 个类别以外的任何分布（OOD）。
训练集是部分ID样本，测试集是部分ID样本和部分OOD样本。
Eg:ID类：猪，牛，羊；OOD类：玫瑰花，桌子
训练集：牛23，羊110，羊18，猪19，牛88，猪56，羊25
测试集：牛80，猪17，玫瑰花16，牛10，猪236，牛29，玫瑰花45，桌子16，桌子28，猪70
任务：检测测试集中的OOD样本。
以MSP为例：OOD score = 1 - max(probs)
测试时，需要对ID样本分类，还需区分该样本是ID还是OOD.
OODD是一个独立的任务，而不是分类的附加任务。

2.  分布外泛化的核心任务？=域泛化
旨在未知分布偏移下获得满意的泛化性能，提高模型在看不见的目标域上的鲁棒性和泛化能力，测试数据来自一个完全未见过的新域，模型需要在这个新域上仍然 正确分类。
域适应：域适应在训练过程中，源域与少量目标域数据能访问
域泛化√：只能访问若干个用于训练的源域数据，测试数据是不能访问的。


3.  离群值检测的核心任务？在给定的一组观测值中找出与显著偏离多数样本的观测点，它不依赖训练–测试划分，也不需要建模类别，而是通过密度、距离或聚类等方式直接从混合数据中筛选出异常值。
由于离群值检测不遵循训练测试程序，而是可以访问所有观测值，所以属于Transductive设置，封闭世界。OD 的“in-distribution”不是训练集决定，而是由观察数据的“多数”决定。
OD 的任务：直接从观测记录中筛选出那些明显不可能或偏离规律的数据。Eg:年龄写成 300 岁;年收入写成 -50000

4.  开集识别和OODD的区别？
OODD 的目标是区分“已知”（ID）和“未知”（OOD）；而 OSSSL 的目标是在区分“已知”和“未知”的同时，还要对“已知”类别进行准确分类。**xxxxx**OODD也要进行ID分类。
OSR基准通常将一个多类分类数据集按类拆分为ID和OOD两部分，而OOD检测以一个数据集为ID，在保证ID/OOD数据集之间类别不重叠的情况下，找到其他几个数据集作为OOD.

开放集识别与多类新颖性检测相同，唯一的区别是开放集识别进一步需要ID分类。分布外检测解决了与开集识别相同的问题。它的典型目标是在不损失ID分类精度的情况下检测具有语义偏移的测试样本。

-----
## 异常检测，多类新颖性检测，开集识别，分布外检测，离群值检测
传统的图像上的各类问题设定

:sparkles:**Sensory感官异常检测**：测试集样本只存在协变量偏移(对抗样本，域偏移，风格变化，P(X)输入空间偏移，P(Y)标签空间不变)，没有语义偏移，**训练集测试集都是同一个类别**。比如训练集是实际的狗狗照片，测试集中有手绘的狗狗图片；**训练集是无缺陷的工业零件，测试集是有划痕的工业零件**。感官AD只关注语义相同或相似的对象，识别其表面的观察差异。具有感觉差异的样品被识别为感觉异常。eg:艺术品的伪造识别、图像取证、工业检查...
:sparkles:**语义异常检测**：P(Y)偏移，**训练集通常只有一个类别(数量充足，覆盖该类内常见变化,如姿态、光照、噪声)，测试集同时包含：①与训练集同类的正常样本；②任意其他语义类别的样本**。目标是检测属于新类别的样本。正常类即训练集只有一个类别，<span style="color:red">eg:MNIST训练集仅含数字“0”，测试集混入“1~9”图像；模型需把非“0”数字全部标为异常。</span>
这种设定下，**训练集和测试集的域必须一致**：
Domain shift的例子：晴天图片/雨天图片(自动驾驶模型在雨天失效)；A医院CT机/B医院CT机(肺结节检测灵敏度下降);正式新闻语料/微博口语(情感分析准确率掉10%)。
如果训练集包含晴天的汽车和雨天的汽车图片，不再叫域偏移。因为训练分布P里同时包含晴天和雨天样本，测试分布Q即便也是晴天/雨天，其分布与P一致，模型在训练阶段已经见过这两种外观，因而不属于域偏移。
正常=分布内，异常=分布外。

:sparkles:**单类新颖性检测**：训练集只有一个类。
:sparkles:**多类新颖性检测**：训练集有多个类，测试集样本存在语义(标签)偏移。目标是把测试集中的样本分为ID类或OOD类，二分类问题，不用进一步区分ID类。<span style="color:red">Eg:用于多类ND的相应MNIST基准可以在训练期间使用前6个类，并且在剩余的4个类上测试作为OOD。</span>
**新颖性检测与语义异常检测的问题设定一样，语义AD可以进一步分为单类语义AD和多类语义AD**。但是，**ND应该是完全无监督的（训练中没有新的数据），而AD可能有一些异常样本作为训练样本。**
AD和ND都不需要对ID数据进行分类。这是和OSR，OOD检测之间的关键区别。

:sparkles:**开集识别**(开放类别检测，开集学习)：目标是需要把ID类分类，OOD类检测出来。
OSR的目标在很大程度上与多类ND的目标相同，唯一的区别是OSR要求从P（Y）中对ID样本进行准确分类。<span style="color:red">Eg:MNIST上的示例学术benchmark可以与多类ND相同，多类ND将前6类视为ID，其余4类视为OOD。此外，OSR进一步要求在6个ID类上有一个好的分类器。</span>

:sparkles:**分布外检测**：分布外检测解决了与开集识别相同的问题。它的典型目标是在不损失ID分类精度的情况下检测具有语义偏移的测试样本。
OOD检测旨在从测试样本中检测不同于训练分布的样本，分布的定义将根据目标中的应用来定义。对于大多数机器学习任务，分布应该指“标签分布”，这意味着OOD样本不应该有与训练数据重叠的标签。训练集通常包含多个类，OOD检测不应损害ID分类能力。
<span style="color:red">Eg:一个示例学术benchmark是在训练期间使用CIFAR-10作为ID，在测试时将CIFAR图像与其他数据集（如SVHN等）区分开来。应该注意，在构建基准时，OOD数据集（如SVHN）不应该与ID数据集有标签重叠。</span>例如：训练识别数字，在测试中遇到猫、狗、汽车，视为 OOD
OSR&OOD区别：
(1)不同的基准设置:OSR基准通常将一个多类分类数据集按类拆分为ID和OOD两部分，而OOD检测以一个数据集为ID，在保证ID/OOD数据集之间类别不重叠的情况下，找到其他几个数据集作为OOD.
(2)OSR没有引入分布外数据：由于理论上开放风险约束担保的要求，OSR不鼓励在设计训练期间使用额外数据。这种限制排除了为了更有效性能改进（例如，outlier exposures）但可能违反OSR约束的方法。
(3)OOD检测的广泛性：与OSR相比，OOD检测包含更广泛的学习任务（例如，多标签分类）
:sparkles:**离群值暴露方法**：一种有效的性能提升技术。它通过在训练时故意引入大量来自未知但易于获取的外部数据集（即“离群值”数据），并将它们作为一个大的“未知”类别进行训练。模型在训练时就“暴露”给了各种非目标数据，从而学会将这些非目标数据推向一个低置信度的区域。这在实际应用中显著提升了模型拒绝真正未知样本的能力。虽然 OE 的性能非常好，但在那些坚持寻求严格理论开放风险保证的 OSR 框架中，它被视为一种不符合约束的方法。

:sparkles:**离群值检测**：封闭世界场景。异常值检测直接处理所有观测值，旨在从受污染的数据集中选择异常值。由于离群值检测不遵循训练测试程序，而是可以**访问所有观测值**，因此解决该问题的方法通常是**传导性**的，而不是归纳性的。
Eg:MNIST上构建异常值检测基准，应该选择一个类别，以便属于该类别的所有样本都被视为内点。来自其他类别的一小部分样本作为待检测的异常值被引入。

![](images/![alt%20text](image.png).png)

**域适应（DA）和领域泛化（DG）**：遵循“开放世界”假设。与OOD检测设置不同，DA/DG期望在测试期间存在协变量偏移，而没有任何语义偏移，并要求分类器对同一组类别进行准确预测。注意，OOD检测通常涉及检测语义偏移，这是对DA/DG的补充。
DA和DG之间的区别在于，**域自适应需要来自目标域的额外但很少的训练样本**，而域泛化不需要。

**Novelty Discovery**：需要像离群值检测一样提前给出所有观察结果。观察以**半监督**的方式提供，目标是发现未标记集中的新类别。与异常值稀疏的异常值检测不同，新颖性发现设置中的未标记集可以大部分由未知类组成，甚至被未知类淹没。

**Zero-shot learning**:具有类似的新颖性发现目标，但遵循训练-测试方案。测试集处于具有未知类的“开放世界”假设下，该假设期望仅在已知类上训练的分类器在标签关系等额外信息的帮助下对未知测试样本执行分类。

:sparkles:**开放世界识别**：目标是ID类分类，OOD类聚类。旨在构建一种终身学习机器，可以主动检测新颖的图像，将其标记为新类，并进行持续学习。它可以被视为新颖性检测（或openset识别）和增量学习的结合。更具体地说，开放世界识别扩展了OSR的概念，增加了随着时间的推移逐渐学习新类的能力。在开放世界场景中，系统不仅可以识别未知实例，还可以更新其模型以将这些新类作为已知集合的一部分。这种方法更加动态，适合环境不是静态的真实世界应用，新的类别可以在初始训练阶段后出现。

---
Related Work
### OODD
1. classification-based models：主要利用模型的输出，如softmax分数，来识别OOD实例。
#### Output-based Methods
**(1) Post-hoc Detection(Training-free)**：
- ODIN使用温度标度和输入扰动来放大ID/OOD可分离性，认为足够大的温度具有很强的平滑效果
- 基于能量分数：具有较低能量的测试样品被认为是ID
- 分层马氏距离/Gram Matrix
- 错误使用基于 ID 数据估计的 BatchNorm 统计量，从而导致异常激活：ReAct、NMD、DICE 与 ASH 分别从激活裁剪、BN 统计偏差、权重稀疏化与特征大幅剪枝等角度减少 OOD 激活噪声

**(2) Training-based** 置信度可以通过设计置信度估计分支或与leave-out策略，对抗训练，数据增强结合
- G-ODIN专门设计训练目标，把在ID上的扰动作为超参数
- 过度自信问题可以通过Logit归一化（LogitNorm）来缓解，在训练中对logits实施恒定向量范数来简单修复常见的交叉熵损失
- 重新设计标签空间：将大的语义空间排列成已知类的层次分类法；在重新设计的标签架构下，运用自上而下的分类策略和组softmax训练
- 将每个类别表示为多个来自不同 NLP 模型的语义词向量

#### Outlier Exposure方法：
**(1)Real Outliers**:训练期间利用一组收集的OOD样本或“异常值”来帮助模型学习ID/OOD差异
- 对给定OOD样本进行平坦/高熵预测
- 抑制OOD特征量
- 使用具有两个分支的网络，这两个分支之间的熵差异对于OOD训练数据被放大
- outlier mining/adversarial resampling获得OOD紧凑而有代表性的集合
- MixOE建议在ID和“远”OOD图像之间进行插值，以获得信息丰富的异常值，从而更好地进行正则化
- 更实际的场景，其中给定的OOD样本包含ID样本，因此使用伪标记或ID过滤方法和最佳传输方案来减少ID数据的干扰.
离群值暴露方法对OOD训练数据的可用性做出了很强的假设（很可能不存在OOD训练样本），这在实践中可能很难获得。此外，需要执行仔细的重复数据消除，以确保异常值训练数据不包含ID数据。

**(2)Data Generation**:当没有OOD样品可用时，一些方法尝试合成OOD样品以实现ID/OOD可分离性。
- 利用GAN来生成OOD训练样本并强制模型预测是一致的
- 在低密度区域生成边界样本
- 生成高置信度OOD样本[165]，或者使用元学习来生成更新样本
- 从特征空间中的低似然区域合成虚拟离群值，将特征空间建模为类条件高斯分布
- 合成导致最差判断的硬OOD数据，以用最小-最大学习方案训练OOD检测器

#### Gradient-based Methods xxx
- ODIN提出通过添加从输入梯度获得的小扰动来使用输入预处理。ODIN扰动的目标是通过强化模型对预测标签的信念来增加任何给定输入的softmax分数。最终，已经发现扰动在ID和OOD输入的softmax分数之间产生更大的差距，从而使它们更可分离
- GradNorm从梯度空间显式地导出评分函数。GradNorm采用梯度的向量范数，从softmax输出和均匀概率分布之间的KL散度反向传播。
虽然基于梯度的方法是有效的，但它们的成功不一定取决于梯度，而是取决于学习的特征嵌入大小和预测的输出分布。
#### Bayesian Models
明显缺点是预测不准确和计算成本高

#### Density-based Methods：低密度区域的测试数据标记为OOD
- 当ID包含多个类别时，类别条件高斯分布可以显式地对分布内建模，以便可以基于它们的可能性来识别OOD样本
- 概率模型有时会为OOD样本分配更高的可能性。一些工作试图使用似然比来解决
生成模型的训练和优化可能极具挑战性，并且性能通常落后于基于分类的方法

#### Distance-based Methods：测试OOD样本应相对远离分布内类的质心或原型
- 使用到所有类质心的最小马氏距离进行检测
- 非参数最近邻距离。与Mahalanobis不同，非参数方法不对底层特征空间施加任何分布假设
- 使用测试样本特征和类别特征之间的余弦相似性来确定OOD样本
- 利用输入的嵌入和类质心之间的径向基函数核
- 欧几里得距离和测地线距离
- 除了计算样本和类质心之间的距离之外，主空间的正交补空间中的特征范数在OOD检测中是有效的
- CIDER探索了超球面空间中嵌入的可用性，可以鼓励类间分散和类内紧凑性
#### Reconstruction-based Methods
核心思想是，在ID数据上训练的编码器-解码器框架通常对ID和OOD样本产生不同的结果。模型性能的差异可以用作检测异常的指标。例如，仅由ID数据训练的重建模型不能很好地恢复OOD数据，因此OOD可以被识别。
具有像素级比较的基于重建的模型由于其昂贵而似乎不是OOD检测中的流行解决方案,用隐藏特征重建被证明是一种有前途的替代方案。
- MoodCat不是重建整个图像，而是屏蔽输入图像的随机部分，并使用基于分类的重建结果的质量来识别OOD样本。
- READ通过将原始像素的重建误差变换到分类器的潜在空间来组合来自分类器和自动编码器的不一致性。
- MOOD表明，与对比训练和经典分类器训练相比，用于预训练的掩蔽图像建模有利于OOD检测任务。

实验表明的事实：
(1)事后方法通常优于训练
(2)大量离群值数据用于训练，仅提升了nearOOD性能
(3)最有效的方法是那些使用模型不确定性和数据增强技术的方法。
(4)一些AD方法擅长Far-OOD
(5)优化ID类的聚类紧凑性可以促进改进的分类和基于距离的OOD检测性能
[Generalized Out-of-Distribution Detection: A Survey]

---------
OODD方法的**本质**--20251125
[Generalized Out-of-Distribution Detection: A Survey]
1. 基于分类

1.1 基于输出 
(1)事后检测：无需修改训练流程和目标函数
   - **概率**：
     - 起源：使用最大 Softmax 概率判断；
     - ODIN 设置足够大的温度参数可产生强烈的平滑效应，**输入扰动**，对于ID样本就像把它轻轻推向他所属类别的“引力中心”，使其更加“典型”。OOD样本由于不属于任何类别，这种扰动反而会使其行为更加“怪异”，从而与ID样本的差距拉大。
   - **能量分数**：能量分数越低的测试样本，越可能属于分布内数据。能量和概率之间可以通过Gibbs分布建立联系，因此二者本质是一样的。
   - //****减少OOD-ID边**:避免图传播时OOD和ID节点特征相互污染
  
 (2)基于训练：在训练阶段，可通过多种方式提升模型的置信度估计能力
    - **设计损失函数**：G-ODIN设计去混淆损失函数；LogitNorm对常用的交叉熵损失函数进行了简单修改，在训练过程中强制对数几率向量的范数保持恒定

 1.2 离群点暴露:训练过程中引入收集到的分布外样本,帮助模型学习分布内与分布外样本的差异
 - **关注如何定义未知**(增强分布外样本预测的平坦性，高熵性)：熵最大化：强制模型对OOD样本的输出接近均匀分布，表示无法判断;弃权类：新增一个未知类别，为OOD提供一个明确的输出目标，概念清晰直接。
 - **关注如何生成高质量离群点**：真实OOD数据；通过Mixup（如MixOE）生成“信息量丰富”的边界样本；在特征空间（如VOS）合成

1.3 **基于梯度**：
     - 输入**梯度微小扰动**增强模型对输入预测标签的置信度，进而扩大分布内与分布外样本的 Softmax 分数差异
     - GradNorm通过KL散度衡量模型的预测与“最大不确定性”（均匀分布）的差距。_最大化KL散度，就等同于最小化模型预测的熵_。
     - 尽管基于梯度的方法效果显著，但其实效性并非依赖梯度本身，而是取决于学习到的特征嵌入幅度和预测输出分布。

2. 基于密度:概率模型显式建模分布内数据，将位于低密度区域的测试样本判定为分布外样本。
- 本质：放弃使用判别式模型（如分类器）的决策边界，转而寻求对ID数据本身的生成过程进行显式建模。
- 准则：设定一个**阈值**λ，若P(x)<λ，则判定x为OOD。
- 研究点
  - 如何设计更鲁棒的评分函数：似然比：不再问这个样本的绝对概率有多高，而是问这个样本作为ID数据的概率，是否显著高于它作为背景噪声。 
  - 改进概率模型本身 

3. 基于距离：特征空间中，ID样本会紧密地聚集在各自类别的原型或中心周围，而OOD样本则会游离在这些紧凑的ID簇之外，与所有ID类别中心都保持相对较远的距离。
- 本质：将OOD检测问题转化为一个在特征空间中的邻近性问题
- 研究点：
如何衡量远近(距离函数的选择)：马氏距离；余弦相似度；最近邻距离；测地线距离；主空间正交补空间中的特征范数
- 准则：**阈值**

4. 基于重建：
- 本质：
- 研究点：
  - 重建空间的选择：如像素空间 vs. 特征空间
  - 重建任务的设计，如何让模型暴露其无知：如直接重建vs.掩码重建(仅重建被掩码的区域)
- 实现流程：编码-解码：将高维的复杂的输入数据（如图像的像素）压缩到一个低维的、稠密的潜在空间中(输入数据x 通过编码器神经网络（通常是一系列卷积层和池化层），被转换为一个潜在向量z,z被认为是输入数据最核心、最重要的特征的抽象表示。理想情况下，它去除了冗余信息（如噪声），保留了语义信息)----将潜在空间中的抽象表示z还原回原始的数据空间，得到一个重建的样本(潜在向量z通过解码器神经网络（通常是一系列反卷积层或上采样层），被转换回与原始输入x 尺寸相同的重建数据)
- 准则：计算**重建差异**度
  - 直接比较原始输入x和重建输出$\hat x$在像素级别的差异，均方误差/平均绝对误差
  - 特征空间重建误差:为了更关注语义信息而非像素细节，将x和$\hat x$同时输入一个预训练的特征提取器（如分类器），在特征空间计算差异,s(x)=f(x)−f($\hat x$)，其中f(⋅) 是特征提取函数。






































