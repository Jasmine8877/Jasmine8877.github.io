---
layout: post
title: "Graph out-of-distribution learning"
subtitle: "About Domain Adaptation, Out-of-distribution"
date: 2025-11-25
author: "曾婉馨"
header-img: "img/post-bg-2015.jpg"
tags: []
mathjax: true

---
### 图域自适应GDA
目标:学习一个具有源域和目标域的最优图学习模型f θ*，使得它可以在目标域上实现最小损失。
在图域自适应(GDA)中，源分布Psrc和目标分布Ptgt在训练期间都是可用的。源域分布与目标域分布不一致，但两域共享相同的分类空间，类别集合为𝑌={1,…,𝐶}。

### 图分布外学习
给定一个训练图 $G_{tr} = (X_{tr}, A_{tr}, Y_{tr})$，它遵循分布 $P_{tr}$，其中训练标签 $Y_{tr}$ 属于已知类别集合 $Y_{tr} = \{1, \ldots, C\}$；同时给定一个测试图 $G_{te} = (X_{te}, A_{te}, Y_{te})$，它遵循分布 $P_{te}$，其中测试标签 $Y_{te}$ 属于 $Y_{te} = \{1, \ldots, C, C + 1, \ldots\}$。这表明测试图可能包含来自 $\{C + 1, \ldots\}$ 的未见过的新节点类别，并且训练分布 $P_{tr}$ 与测试分布 $P_{te}$ 不同。

**①开放世界图学习**（Open-World Graph Learning）旨在学习一个最优的图函数 $f_{\theta}^{*}$，使其不仅能在训练分布 $P_{tr}$ 上实现最小损失，还能在测试分布 $P_{te}$ 上实现最优性能。
任务:在保持已知类 $C$ 的高准确率的同时，将所有新类 $\{C+1, \ldots\}$ 归类为 "unknown"。
训练集设定： $G_{tr} \sim P_{tr}$，标签 $Y_{tr} = \{1, \ldots, C\}$（已知类）。
测试集设定： $G_{te} \sim P_{te}$，标签 $Y_{te} = \{1, \ldots, C, C+1, \ldots\}$（包含已知类和新类）

损失函数的设计必须体现出开放世界图学习的双重目标：
- 已知类别的分类准确性（在 $G_{tr}$ 上的性能）：已知类分类损失（ID loss），确保模型在 $C$ 个已知类别上的准确性（例如，标准的交叉熵损失）。
- 新类别的检测能力（将 $G_{te}$ 中的 $\{C+1, \ldots\}$ 识别为 "unknown"）：OOD 检测损失（OOD Loss）： 鼓励模型对属于 $\{C+1, \ldots\}$ 的新类输入产生低置信度，从而更容易被归类为 "unknown"。

:warning:Note:
1. 在开放世界图学习中，训练时只有训练图分布可用，测试分布不可用

**②图OODD ：**
任务仅聚焦于检测未见过的类别节点时，开放世界图学习便退化为图 OOD 检测问题。
任务定义： 将问题简化为一个二分类问题：判断一个测试样本（节点）是来自于已知类别 $Y_{tr}$ (Seen) 还是新类别 (Unseen)。
训练集设定： $G_{tr} \sim P_{tr}$，标签 $Y_{tr} = \{1, \ldots, C\}$。
测试集设定： $G_{te} \sim P_{te}$，标签 $Y_{te} = \{1, \ldots, C, C+1, \ldots\}$（包含已知类和新类）
关注点： 类别空间的变化。目标是准确地将所有 $\{C+1, \ldots\}$ 的节点识别出来。

**③图OODG(图域泛化)**
当测试过程中没有unseen类，模型只关注特征分布的偏移（即Pte和Ptr之间的差异），开放世界图学习问题将退化为**图OOD泛化**问题。
任务定义：模型只需关注由 特征分布偏移 ($P_{tr} \neq P_{te}$) 引起的问题。目标是学习领域不变（Domain-Invariant）的特征，确保模型在测试集 $G_{te}$ 发生特征分布偏移时，对 $C$ 个已知类别的分类性能不下降。
    - 特征分布偏移引起的问题：模型学习到了**虚假相关性**（Spurious Correlations），而不是因果不变特征（Causal Invariant Features）。当训练和测试的分布不同时，模型可能会利用**训练集中的易变特征**（与任务无关、但与训练环境强相关）进行预测，一旦测试环境变化（即 $P_{tr} \neq P_{te}$），性能就会急剧下降
训练集设定： $G_{tr} \sim P_{tr}$，标签 $Y_{tr} = \{1, \ldots, C\}$。
测试集设定： $G_{te} \sim P_{te}$，关键约束是 $Y_{te} = Y_{tr}$（无新类）。
关注点： 分布/领域的变化。目标是克服图结构、节点特征或边的统计特性变化对模型决策的影响
- 图OOD泛化、图OOD检测和开放世界图学习统称为图分布外学习。

| 任务 | 测试集 $Y_{te}$ 的真实标签空间 | 模型的预测目标空间 $Y$ | 目标 |
| :--- | :--- | :--- | :--- |
| **开放世界图学习** | $\{1, \ldots, C, \mathbf{C+1}, \ldots\}$ | $\{1, \ldots, C, \mathbf{unknown}\}$ | 多分类（已知类）+ 检测（新类 $\to$ unknown） |
| **图 OOD 检测** | $\{1, \ldots, C, \mathbf{C+1}, \ldots\}$ | $\{\mathbf{Seen}, \mathbf{Unseen}\}$ | 二分类（是否是新类） |
| **图 OOD 泛化** | $\{1, \ldots, C\}$ | $\{1, \ldots, C\}$ | 多分类（已知类） |

### 相关工作
1. **基于增强**→**(对应离群值暴露)**
(1)数据增强：对图结构/特征进行扩充，增加训练数据的多样性。
结构增强:针对图级
特征增强:SMUG 在元训练阶段引入 “沙混” 策略，将已知类别与模拟的分布外样本相结合，使模型在没有真实分布外样本的情况下也能识别分布外数据；GOODAT融入信息瓶颈理论，在测试阶段增强了对分布外样本的区分能力(Post-hoc)。
- 研究点：
  - 如何合成有效的“负样本”？

(2)模型增强:通过正则化、对抗训练、注意力机制等技术，对图神经**网络架构**或**训练策略**进行改进。
- 本质：通过修改模型的内在结构、训练策略，将分布外检测的能力直接植入模型之中，使模型自身成为一个天然的OOD检测器。
举例：
- GPN-CE-GD引入基于距离的正则化，在损失函数中鼓励模型将同类节点的特征聚集到“原型”周围，并让不同类别的原型彼此远离。这直接优化了类内紧凑性和类间分离性。OOD样本因为没有对应的原型，其特征会自然地落在这些紧凑簇的间隙地带；
- GraphDE在推理时，通过多次采样或计算分布方差，直接得到预测的不确定性。高不确定性即对应OOD样本。
- GOLD通过在ID数据上施加特定扰动，或利用生成模型，来合成“伪OOD”样本。模型通过尝试区分ID和这些“伪OOD”样本，间接学习了决策边界。

对比：
数据增强像是在给一个学生提供各种奇怪的练习题（OOD），希望他能自己悟出考试范围（ID边界）。
|
模型增强则像是直接改造学生的大脑认知架构，让他能清晰地知道自己的知识边界在哪里。它不依赖于提供具体的OOD样例，而是让模型在学习ID任务的过程中，自发地形成对未知的警惕性。

2. **基于重建**:借助生成模型学习训练数据的分布特征，并对数据样本进行重构，通过评估重构质量来判断样本属于分布内还是分布外的概率
本质：利用生成模型来学习和定义什么是正常
举例：
- OpenWGL采用带约束的变分图自编码器对节点不确定性进行建模。引入了标签损失和类别不确定性损失，不仅让模型学习分布内数据的特征，还使其对分布外数据保持敏感。其中，标签损失用于最小化标记数据的交叉熵损失，类别不确定性损失则通过最大化熵来增强对未知节点的区分能力；
- OSSC 将动态变分自编码器（DVAE）与图卷积网络（GCN）相结合，能够处理图数据中的结构变化和时序变化。通过学习每个节点的一系列潜在分布，OSSC 方法可以捕捉节点属性和图拓扑结构的演变过程。

3. 基于信息传播:利用图的结构特性进行关键信息聚合，通过捕捉节点邻域的核心特征来实现分布外检测
(1)特征传播：
本质：在聚合邻居特征时，如何防止 OOD 节点携带的噪声和错误信息破坏 ID 节点的特征表示。
举例：
- LMN在变分推理框架中引入了一个潜在变量来指示分布内或OOD节点，并进一步提出了一种名为学习混合邻居（LMN）的新算法，该算法通过典型图神经网络中的消息传递来学习抑制OOD节点
- OODGAT在特征传播过程中，通过注意力机制明确区分分布内节点和分布外节点；
- GERDQ借助深度 Q 学习调整边权重，减轻分布外节点对模型的影响；
- GRASP提出边增强策略，优化了内部边与外部边的比例。
- Relation通过构建关系图捕捉节点间的复杂交互，以此区分分布内数据和分布外数据；
- Open-WRF是一种弱监督相关反馈方法，通过融合图邻域信息识别分布外类别，降低了模型对分布外检测阈值的敏感度。
(2)能量函数→(对应能量分数)
- 研究点：如何定义能量和如何传播能量
- 举例：
  - GNNSafe(基于分类器输出的能量):直接利用经过标准分类损失训练的GNN最后一层的logits计算能量，如果模型对所有类别的输出概率都很低（即置信度低），那么能量就会很高。
  - TopoOOD(基于拓扑结构的能量):OOD节点可能表现出与ID节点不同的局部拓扑结构。例如，它们的连接模式可能更“混乱”或“无序”。使用 k阶狄利克雷能量 等图信号处理工具来量化局部邻域的拓扑平滑度或无序程度
  - EnergyDef(基于节点密度估计的能量):在特征空间估计节点的概率密度。位于低密度区域的节点被赋予高能量。

:sunflower:关系：低概率 → 高能量 → 低密度 → 远距离

(3)不确定性传播
- 直觉：身边的大多数朋友都对某个信息表示怀疑（高不确定性），那么你也很可能受到影响而变得不确定
- 研究点：如何定义不确定性和如何模拟传播过程
- 举例
  - GPN计算贝叶斯后验，量化模型预测的方差。后验分布越分散（方差大），说明模型越不确定
  - NGC利用标签传播技术。节点的不确定性会随着传播过程暴露，并与邻域信息相互校正。一个与大多数邻居标签都不一致的节点，其自身标签很可能是有噪声的或它本身就是OOD。研究问题：如何设计抗噪的传播算法，避免将错误标签或OOD节点的“污染”扩散到整个图？
  - 扩散过程

4. 基于分类: 在图数据分布外检测任务中，通过训练分类器来判断样本属于已知类别还是未知类别
(1)概率证据分类：证据可以理解为支持模型做出某个预测的数据支持强度。高总体证据 → 狄利克雷分布集中 → 低认知不确定性（模型很确定）
- 研究点：如何从模型输出中获取证据和 如何利用狄利克雷分布量化不确定性
(2)边界优化分类：通过优化分类器的决策边界，增强对分布外样本的区分能力。将ID数据的决策区域塑造成一个紧凑的、有明确边界的集合。在模型学习“这是什么”的同时，也学习 “哪里是已知世界的尽头”
- 研究点：如何干预和在哪个层面干预
- 举例：
  - AAGOD创造“挑战性”的ID样本，模拟边界情况。 它不是简单地增加数据量，而是有针对性地增强那些对区分ID和OOD至关重要的模式
  - EL在损失函数中引入明确的指令，直接扩大ID样本与决策边界之间的安全距离。提出的激励损失函数，其核心思想是奖励那些不仅分类正确而且远离决策边界的ID样本。鼓励模型将ID样本的特征向量推向类别原型的中心，从而在类别之间和ID区域之外创造出更宽的“空白地带”（Margin）。OOD样本落入这些空白地带的概率就大大增加了。
  - UGNN在特征空间中为已知类别建立“原型”或“锚点”，并明确地划定这些原型所覆盖的语义区域。 任何不属于这些区域的样本都被视为OOD。


参考文献：
[1] Graph Learning under Distribution Shifts: A    Comprehensive Survey on Domain Adaptation, Out-of-distribution, and Continual Learning
[2] 关于方法的本质及研究点总结→Deepseek


