---
layout: post
title: "base_semi"
subtitle: "半监督学习基础"
date: 2025-11-12
author: "曾婉馨"
header-img: "img/post-bg-2015.jpg"
tags: []
mathjax: true

---

1. 半监督学习技术分类：
(1) 伪标记 
  - 自我训练
    - 思想：在标记的数据集上预先训练一个模型，并通过预测未标记的数据迭代地重新训练或微调模型本身。
    - 核心：提高伪标签的质量
  - 共同训练
    - 思想：使用单个模型时，自我训练的伪标签质量通常会有很大差异。因此，结合多个模型生成更稳健的伪标签非常重要

(2) 一致性正则化(Consistency Regularization):由于使用伪标签会增加训练不稳定的风险，因此引入了一致性正则化项来指定假设的先验约束。
(3) 基于 GAN 的方法
(4) 基于对比学习的方法
(5) 混合方法:各种match方法属于一致性正则和伪标签的混合方法
1. 半监督学习的主要目标是通过利用大量未标记的数据来提高监督学习的性能。
就是对没有标签的数据打标签，打完标签的这些数据还要拿来做监督学习，相当于一个数据（or标签）生产器。
1. 半监督主要方法：EM算法；自训练；协同训练；转导SVM；基于图的方法
2. 要利用未标记样本,必然要做一些将未标记样本所揭示的数据分布信息与类别标记相联系的假设.最常见的是“聚类假设”(cluster assumption),即假设数据存在簇结构,同一个簇的样本属于同一个类别.图 13.1 就是基于聚类假设来利用未标记样本,由于待预测样本与正例样本通过未标记样本的“撮合”聚在一起,与相对分离的反例样本相比,待判别样本更可能属于正类，半监督学习中另一种常见的假设是“流形假设”(manifold assumption),即假设数据分布在一个流形结构上,邻近的样本拥有相似的输出值.“邻近”程度常用“相似”程度来刻画,因此,流形假设可看作聚类假设的推广,但流形假设对输出值没有限制,因此比聚类假设的适用范围更广,可用于更多类型的学习任务.事实上,无论聚类假设还是流形假设,其本质都是“相似的样本拥有相似的输出”这个基本假设.
3. 半监督学习可进一步划分为
- 纯(pure)半监督学习：训练数据中的未标记样本并非待预测的数据；基于“开放世界”假设,希望学得模型能适用于训练过程中未观察到的数据
- 直推学习(transductivelearning)：假定学习过程中所考虑的未标记样本恰是待预测数据,学习的目的就是在这些未标记样本上获得最优泛化性能。直推学习是基于“封闭世界”假设,仅试图对学习过程中观察到的未标记数据进行预测
1. 模型
PiModel (NeurIPS 2015) [1]
MeanTeacher (NeurIPS 2017) [2]
PseudoLabel (ICML 2013) [3]
VAT (Virtual adversarial training, TPAMI 2018) [4]
MixMatch (NeurIPS 2019) [5]
UDA (Unsupervised data augmentation, NeurIPS 2020) [6]
ReMixMatch (ICLR 2019) [7]
FixMatch (NeurIPS 2020) [8]
FeatMatch (ECCV2020)
FlexMatch (NeurIPS 2021) [9]
SimPLE:Similar Pseudo Label Exploitation for Semi-Supervised Classification (CVPR2021)
UPS:In Defense of Pseudo-Labeling: An Uncertainty-Aware Pseudo-label Selection Framework for Semi-Supervised Learning（ICLR2021）
FreeMatch (ICLR 2023) [10]
SoftMatch (ICLR 2023) [11]
7. 快速总结近期半监督学习方法中的共同主题，其中许多旨在减少确认偏差(确认偏差是不完美的教师模型提供不正确伪标签而产生的问题。过度拟合错误的标签可能不会产生一个更好的学生模型)：
通过先进的数据增强方法将有效且多样化的噪声应用于样本。
在处理图像时，MixUp是一种有效的增强方法。Mixup也可以用于语言，从而带来小的增量改进（Guo et al. 2019）。
设置阈值并丢弃置信度低的伪标签。
设置每个小批量标记样本的最小数量。
锐化伪标签分布以减少类别重叠。
9. Sharpening 锐化操作(温度缩放)
概念：Sharpening 通过压缩预测概率分布的熵，提升了伪标签的置信度，是半监督学习中平衡未标注数据利用与噪声控制的关键技术。温度参数（0<T<1），T 越小，分布越尖锐。T->0,Sharprn(p,t)->one-hot分布
作用：
- 降低预测熵：未标注数据的模型预测概率分布可能过于平缓（如各类别概率接近），导致伪标签噪声大。通过 Sharpening 使概率分布更“尖锐”，即增大预测概率最大值与其他值的差距
- 降低噪声：调整模型的预测分布，使得高置信度的预测更加突出，低置信度的预测更加抑制。筛选高置信度伪标签，提升伪标签质量
- 与一致性正则化的协同：对同一未标注样本的不同增强版本，强制其锐化后的预测一致，增强模型鲁棒性。
注意：
- 初始尝试T=0.5，根据任务调整（文本任务可能需要更小的T
- 过小的T会导致过度自信，可能丢失潜在正确样本
- 监控模型在验证集的表现，避免因过度过滤导致欠拟合
☆：sharpening降低预测熵的原理？
通过sharpening操作，模型的预测分布变得更加集中，高置信度的预测被进一步增强，低置信度的预测被进一步抑制。这种集中化的分布使得熵减小，因为不确定性降低了。
假设模型的预测概率分布为 p=(0.7,0.2,0.1)，我们使用温度参数 T=0.5 进行sharpening：![Alt text]({{site.baseurl}}/img/inpost/image.png)

10. 对于任何值λ，其分布特性与1−λ的分布特性相同：表示λ和1−λ在**概率密度函数值**是相等的
11. MixUp方法：混合顺序的问题，x'=0.3x1+0.7x2 和 x''=0.7x1+0.3x2。这两个混合结果确实不同，但它们的差异在于混合的比例，而不是混合的顺序。
12. MixMatch为什么不直接用增强的样本，还要用MixUp混合一下？
相比直接使用增强后的样本，MixUp 更能帮助模型学习到**更平滑的决策边界**，并减少对不可靠伪标签的依赖，因此在 半监督学习 中，它能够有效提高模型的 泛化能力 和 鲁棒性。
- 增强后的样本通常是基于 原始标签 进行变换的，但在多标签或半监督学习的情况下，伪标签的质量可能较低，导致增强样本仍然依赖于不可靠的标签。MixUp 的方法通过将 不同类别的标签进行加权混合，有效缓解了这一问题。
- MixUp 在生成新的样本时，标签是通过加权平均来计算的，这不仅减小了标签噪声的影响，而且增强了模型对标签之间模糊过渡的学习能力。而直接使用增强样本时，标签可能依赖于不准确的伪标签，容易在训练过程中被噪声标签影响。
13. FixMatch 
#### 🧠 FixMatch 是如何预测伪标签的？

**FixMatch** 是一种经典的半监督学习方法，结合了 **伪标签（pseudo-labeling）** 和 **一致性正则化（consistency regularization）**，能够在标注样本极少的情况下，有效利用大量无标签数据。

---

##### 🎯 核心目标

对无标签样本生成高置信度的伪标签，并用这些伪标签训练模型。

---

##### 🔄 FixMatch 伪标签生成流程

##### Step 1：弱增强（Weak Augmentation）

对无标签样本 \( x_u \) 应用轻度图像增强（如随机裁剪、翻转），得到：

$$
x_u^w = \text{WeakAug}(x_u)
$$

---

##### Step 2：模型预测伪标签

使用当前模型预测类别概率分布：

$$
p = \text{softmax}(f_\theta(x_u^w))
$$

取最大概率对应的类别作为伪标签：

$$
\hat{y}_u = \arg\max(p)
$$

---

##### Step 3：置信度阈值筛选

若最大概率大于阈值 \( \tau \)（默认值为 0.95），认为伪标签可信：

$$
\max(p) \geq \tau \Rightarrow \text{使用} \ \hat{y}_u
$$

否则丢弃该样本。

---

##### Step 4：强增强训练（Strong Augmentation）

对原样本 \( x_u \) 进行强增强，得到：

$$
x_u^s = \text{StrongAug}(x_u)
$$

使用伪标签训练其强增强版本：

$$
\mathcal{L}_{\text{unsup}} = \text{CrossEntropy}(f_\theta(x_u^s), \hat{y}_u)
$$

---

##### 🔧 总损失函数

FixMatch 的总损失由监督和无监督部分组成：

$$
\mathcal{L} = \mathcal{L}_{\text{sup}} + \lambda \cdot \mathcal{L}_{\text{unsup}}
$$

- \( \mathcal{L}_{\text{sup}} \)：带标签样本的交叉熵损失  
- \( \mathcal{L}_{\text{unsup}} \)：伪标签指导的无监督损失  
- \( \lambda \)：平衡因子，通常设为 1 或 100

---

##### 🛠️ 核心设计要点

| 环节 | 设计思想 | 示例 |
|------|-----------|------|
| 弱增强预测 | 保留语义特征，用于伪标签生成 | 翻转、裁剪 |
| 高置信度筛选 | 降低伪标签噪声 | \( \tau = 0.95 \) |
| 强增强训练 | 提高模型鲁棒性 | RandAugment、ColorJitter |

---

##### 📌 一句话总结

> **FixMatch 使用弱增强预测高置信伪标签，并用这些标签训练强增强样本，从而高效利用无标签数据。**



code:
```python
for epoch in range(epochs):
    model.train()
    train_tqdm = zip(labeled_dataloader, unlabeled_dataloader)
    for labeled_batch, unlabeled_batch in train_tqdm:
        optimizer.zero_grad()
        # 利用标记样本计算损失
        data = labeled_batch[0].to(device)
        labels = labeled_batch[1].to(device)
        logits = model(normalize(strong_aug(data)))
        loss = F.cross_entropy(logits, labels)
        # 计算未标记样本伪标签
        with torch.no_grad():
            data = unlabeled_batch[0].to(device)
            logits = model(normalize(weak_aug(data)))
            probs = F.softmax(logits, dim=-1)
            trusted = torch.max(probs, dim=-1).values > threshold
            pseudo_labels = torch.argmax(probs[trusted], dim=-1)
            loss_factor = weight * torch.sum(trusted).item() / data.shape[0]
        # 利用未标记样本计算损失
        logits = model(normalize(strong_aug(data[trusted])))
        loss += loss_factor * F.cross_entropy(logits, pseudo_labels)
        # 反向梯度传播并更新模型参数
        loss.backward()
        optimizer.step()
```
1.  **EMA**(Exponential Moving Average): 
- 定义：![Alt text]({{site.baseurl}}/img/inpost/image-1.png)
- 理解：β越大，表示考虑的时间长度越长。![Alt text](image-2.png)
- 进一步理解：通过迭代可得![Alt text]({{site.baseurl}}/img/inpost/image-3.png) 也就是：$v_{100}$是$\theta_{100}\theta_{99}\theta_{98}...$的加权求和，且$\theta$前的系数之和=1或逼近1。当某项系数小于峰值系数$(𝟏−𝜷)^{𝟏/𝒆}$时，我们可以忽略它的影响:![Alt text]({{site.baseurl}}/img/inpost/image-4.png)
- 更新模型参数的有效性：普通的参数权重相当于一直累积更新整个训练过程的梯度；使用EMA的参数权重相当于使用训练过程梯度的加权平均（刚开始的梯度权值很小）。由于刚开始训练不稳定，得到的梯度给更小的权值更为合理，所以EMA会有效。
1.  一致性 正则化方法的核心思想:模型的输出在现实扰动下保持不变。(对同一未标注样本施加不同扰动（如数据增强、噪声添加），模型应输出相似的预测结果)
**一致性约束**可以在三个层面上考虑：
- 输入数据:从输入数据集的角度来看，扰动通常会被添加到输入示例中：加性噪声、随机增强，甚至对抗性训练。
- 神经网络:我们可以删除网络的一些层或连接，如WCP[66]。
- 训练过程:从训练过程中，我们可以使用SWA使SGD适合某些训练时期的一致性训练或模型的EMA参数作为新参数。
**正则化**作用：约束模型的学习行为，防止过拟合，提高泛化能力。核心思想是施加一个损失项(额外项)，鼓励模型在不同扰动下的预测保持一致。即λ$L_{consistency}$ 一致性损失
1.  同一未标记样本的不同增强形式的偏差是指不同增强方法可能引入不同程度的扰动，导致模型预测存在差异，这种差异即为增强形式的偏差。现有的方法通常忽略了这种偏差，简单地基于样本置信度进行权重分配，而没有考虑到不同增强方式对数据特征的独特影响。
eg：若样本x的弱增强版本αweak(x)预测置信度为 0.95，而强增强版本α strong (x)置信度为 0.6，现有方法可能仅依赖高置信度的弱增强结果，忽略强增强预测的不一致。这种忽略可能导致：
- 噪声伪标签：高置信度但偏差大的预测被错误保留；
- 模型过拟合：模型偏向于拟合易增强（低偏差）样本，忽略难样本。

1.  信息熵：随机变量的不确定性。
定义：对于对于一个离散的随机变量𝑋及其概率分布 $P(X) = \{p_1, p_2, \dots, p_n\}$，有：\[
H(X) = - \sum_{i=1}^{n} p_i \log_2 p_i
\]
性质：
- 信息熵越大，不确定性越大：
- 信息熵的最小值是0,：当某个事件的概率是 1，其它所有事件的概率是 0 时，熵为 0。即没有不确定性时的信息熵为 0。
- 最大值：当所有事件的概率相等时，信息熵达到最大值。例如，对于一个均匀分布的 2 类事件（如抛硬币），熵为 1。
举例：假设我们有一个不公平的硬币，正面朝上的概率是 0.8，反面朝上的概率是 0.2。此时，信息熵为：\[
H(X) = - \left( 0.8 \times (-0.322) + 0.2 \times (-2.322) \right) \approx 0.7219 \text{ bit}
\]，信息熵比公平硬币的 1 比特低，因为不公平硬币的概率分布不均匀，模型的预测更加确定(偏向于正面朝上)。
1.  半监督学习中，计算每个未标记样本的信息熵：。如果一个未标记样本的预测分布非常均匀，表示模型对其标签有很大的不确定性，信息熵较大；如果模型的预测分布高度集中，表示模型对该样本有较高的确定性，信息熵较小。
eg:对于一个未标记样本 \( u \)，模型对其预测为 \( p = \{p_1, p_2, \dots, p_n\} \) 的概率分布，其中 \( p_i \) 是模型对未标记样本 \( u \) 预测为第 \( i \) 类的概率，则该样本的信息熵为：
\[
H(u) = - \sum_{i=1}^{n} p_i \log_2 p_i
\]
**不确定的预测**：假设一个二分类问题，未标记样本 \( u \) 的预测概率为：
\[p = [0.5, 0.5]\]
信息熵计算为：\[H(u) = - \left( 0.5 \log_2 0.5 + 0.5 \log_2 0.5 \right) = 1 \text{ bit}\]
**确定的预测**:假设另一个二分类问题，未标记样本 \( u \) 的预测概率为：\[p = [0.9, 0.1]\]
信息熵计算为：\[H(u) = - \left( 0.9 \log_2 0.9 + 0.1 \log_2 0.1 \right) \approx 0.468 \text{ bit}\]
信息熵在SSL中的作用：
- 筛选伪标签的可信度：在半监督学习中，通常会为未标记样本生成伪标签。模型可以为每个未标记样本计算信息熵，并选择信息熵较小的样本（即模型较为确定的样本）作为高质量伪标签，用于进一步训练。
- 在训练过程中，较低信息熵的未标记样本通常具有较高的信任度，可以用作训练的有力信号。而较高信息熵的样本表示模型对其类别的预测不确定，这些样本的伪标签可能不那么可靠，因此可以被忽略或降低其权重。
1.  最小最大归一化
归一化信息熵的目的: 是为了使得信息熵的值处于一个统一的范围内，通常是 [0, 1]，以便在后续的训练中进行有效的比较和使用。
- **计算方法**：先计算最大信息熵：在均匀分布下，信息熵最大。当每个类别的概率相等时，信息熵达到最大值。对于 5 个类别的情况，最大信息熵为：\[H(u) = - \sum_{i=1}^{5} p_i \log_2 p_i\]。最小信息熵为0：当某个类别的概率为 1，其他类别的概率为 0 时，信息熵最小，即：\[H_{\text{min}} = 0\] 归一化信息熵：\[H_{\text{normalized}}(u) = \frac{H(u) - H_{\text{min}}}{H_{\text{max}} - H_{\text{min}}}\]
- **例子**：假设未标记样本 \( u \) 的预测概率为：\[p = \{0.2, 0.3, 0.1, 0.2, 0.2\}\]
计算信息熵 \( H(u) \)：\[H(u) = - \left( 0.2 \log_2 0.2 + 0.3 \log_2 0.3 + 0.1 \log_2 0.1 + 0.2 \log_2 0.2 + 0.2 \log_2 0.2 \right) =2.137      bits\]
然后，使用归一化公式计算：\[H_{\text{normalized}}(u) = \frac{H(u) - H_{\text{min}}}{H_{\text{max}} - H_{\text{min}}} = \frac{2.137-0}{2.322-0} \approx 0.92 \]
1.  边界熵(bounding entropy)
- **定义**：对未标记样本集的不确定性进行量化的一个重要指标，通常用于指导选择那些具有较高学习价值的样本。
- 计算方式：对所有未标记样本的熵进行加权平均或其他加权机制来计算
- 计算步骤：
  (1)模型预测分布：对于每个未标记样本 \( u_i \)，模型给出该样本属于各个类别的概率分布 \( p(u_i) = \{p_1, p_2, \dots, p_k\} \)，其中 \( p_j \) 表示模型对样本 \( u_i \) 属于第 \( j \) 类的预测概率。
  (2)计算单个样本的熵:对每个未标记样本 \( u_i \)，我们计算其信息熵 \( H(u_i) \)，公式为：\[H(u_i) = - \sum_{j=1}^{k} p_j \log_2 p_j\] 其中，\( p_j \) 是模型对 \( u_i \) 属于第 \( j \) 类的预测概率，\( k \) 是类别数。
  (3)计算整个未标记样本集的界限熵: 我们将**所有未标记样本的熵进行加权平均**，以计算整个样本集的界限熵 \( M_t \)。如果是简单的平均，计算公式为：\[M_t = \frac{1}{n} \sum_{i=1}^{n} H(u_i)\] 如果有权重 \( w_i \)（例如样本的不确定性或重要性），则计算加权熵：\[M_t = \sum_{i=1}^{n} w_i H(u_i)\]
- 意义：
  - 如果界限熵 \( M_t \) 较高，表示模型对样本的预测不确定，可能**存在边界样本**，模型尚未完全确定这些样本的分类。
  - 如果界限熵 \( M_t \) 较低，表示模型对样本的预测较为确定，模型已经能够较好地分类这些样本。
1.   信息熵和边界熵的差异 (不一定对xxxxxxxxxx)
- 信息熵<边界熵：意味着这些未标记样本的分类相对较为确定，模型对它们的预测概率分布较为明确，因此它们的类别标签容易被确定。这些样本通常位于决策边界的远离区域，模型的预测已经具有较高的置信度，因此它们对模型学习的贡献较小。(**自信的分类**：模型已经对这些样本做出了较为准确的预测，因此不需要进一步优化或重新训练。在实际应用中，这些样本可以根据模型的预测**直接分配标签**，无需更多的人工干预。)

1.  根据边界熵Mt，将未标记样本分为两类：
- 利用样本（Exploitation Sample）：信息熵小于Mt的样本，这些样本的预测较为可靠，可以用于主动利用（Proactive Exploitation）。
- 探索样本（Exploration Sample）：信息熵大于等于Mt的样本，这些样本的预测不确定性较高，用于保守探索（Conservative Exploration）。
1.  熵最小化是熵正则化的一种策略，可以防止决策边界通过高密度数据点区域。它可以通过鼓励模型对未标记数据进行低熵预测，然后将伪标记样本添加到标准监督学习设置的标记数据集中来实现SSL。predominantly
-  熵最小化可以防止决策边界通过高密度数据点区域？答：半监督学习中，数据通常服从 流形假设（Manifold Assumption，高维数据点实际分布在低维流形上，相似的样本在高维空间中仍然接近）或 低密度假设（Low-Density Separation Assumption，不同类别的数据点通常被低密度区域（即样本较少的区域）分隔，决策边界应位于低密度区域，而不是高密度区域）。熵最小化能够通过让未标记样本的熵值变小，使模型在未标记数据上给出更确定的预测。
1.  弱增强版本和强增强版本的区别？
弱增强：通常涉及较轻微的数据变换，如图像的翻转、裁剪或轻微的亮度调整。由于变换较为温和，弱增强后的数据与原始数据的差异较小，因此模型的预测相对稳定。主要用于生成一个稳定的基础预测，作为后续强增强的参考点。弱增强后的数据通常用于生成伪标签（pseudo-labels）。
强增强版本：强增强涉及更大幅度的变换，如旋转、剪切、颜色调整等，这些变换会显著改变数据的视觉特征。
​多样性较高：​ 强增强能够生成多样化的训练样本，增加模型的鲁棒性。​目标：​ 通过引入更多的噪声和变化，迫使模型学习更具**泛化**能力的特征表示。

1.  KL散度：
意义：P是真实分布（或目标分布）；Q是模型预测的分布（或近似分布）。KL 散度衡量了当我们用 Q 来近似 P 时，信息损失的大小。KL 散度越小，说明两个分布越相似。
应用：最大熵正则化——控制模型输出分布不要偏离先验分布，保持预测的多样性（常用于半监督学习）。
对模型训练的启发：训练中，如果我们知道标签的先验分布如每类均衡，我们就可以加入 KL 散度作为正则项，惩罚模型输出偏离这个分布，鼓励预测更“均衡”、“探索性强”，尤其在半监督学习或伪标签阶段很重要。
1.  分布？
分布是概率分布的简称：表示某个事件发生的概率是多少。在分类任务中，“分布”一般指的是模型对一个样本属于各个类别的预测概率，
  - 示例：比如你让模型判断一个图中的节点属于哪一类，可能结果是人，动物，地点[0.1,0.7,0.2],这个就是预测的分布，也叫预测概率分布 或 输出分布。它告诉我们模型认为这个样本“属于某一类”的置信度。
  - “预测分布”是模型算出来的，“真实分布”是标签对应的，我们希望这两个越接近越好。
  
1.  开放学习方法：
SSL：遵循封闭世界假设：假设未标记的数据只包含来自可见类别的样本，这是非常严格的。
**novel class discovery (NCD)**：$ \bar{C}$ 假设未标记的数据仅包括新类别样本，对未标记集中的新类样本进行聚类，无法识别已知类的样本。CL∩CU=∅
      - GCD**广义类发现**:改进了

**Robust SSL**：**C+1** transductive setting 健壮SSL关注的是如何避免看不见的类未标记数据的负面影响。
**Open-set recognition (OSR) 即open-set SSL**：inductive setting**C+1** (只是检测而已，仅关注已知类的分类)识别和抑制/丢弃 OOD 样本
  - 开放集半监督学习（OS-SSL）是指用标记和未标记实例学习分类器的任务，但未标记数据可能包含与看不见的标签相关联的实例，称为分布外（OOD）实例。(属于看不见的类的未标记实例称为分布外（OOD）实例)
  - 开集识别和OOD不一样？开集识别只是检测新类，可能是猫狗以外的老虎；OOD检测的是分布外的数据，可能是X光片。
  - 如果指定learned classes (in-distribution) or unknown classes (out-of-distribution)，那么开集识别和OOD是一回事。
未标记数据集中的未知类别被视为**单个类别**，在推理过程中识别新类别样本，开放集SSL方法只是拒绝未知类样本，以避免将它们分配给已知/可见的类别之一，防止它们对未标记数据集中已知类的分类性能产生负面影响
open-world recognition (OWR) ：以增量方式工作，其中一旦模型从新的类中确定实例，oracle就可以为未知样本提供类标签，以将它们合并到所见集合中。
out-of-distribution detection ：
Safe SSL：在标记数据上训练模型，并使用它来检测和删除OOD数据。
Robust SSL：过滤掉或重新加权新类的样本。
**OWSSL**：未标记数据包括标记数据的类别和新的类别，需要识别已知类和对新类的样本进行聚类。与以前的研究相比，开放世界SSL场景更接近现实世界的情况，但仍处于早期阶段。
  - ORCA
  - NACH(Robust semi-supervised learning when not all classes have labels,NIPS2022)


28.     **logits**:在机器学习和深度学习中，logits 是一个关键术语，特**指神经网络最后一层（输出层）的原始预测分数**（raw scores），尚未经过概率归一化（如Softmax）处理
2.   “s.t.” 是“subject to”的缩写，用于表示优化问题中的约束条件。它帮助明确在优化过程中需要满足的限制或条件。
3.  熵正则化以避免将所有样本分配到同一个类中的trivial解决方案（无意义解），为什么?
**问题**：在无监督的聚类或自标签（self-labeling）任务中，模型并没有使用真实标签，而是根据自己的特征表示来尝试分类或聚类。如果我们仅仅最大化模型预测和伪标签之间的一致性（比如交叉熵），没有其他约束的话，模型可能会“走捷径”，把所有样本分到一个类别，这样模型预测就“非常统一”，损失也能低，看起来很“成功”。
但这个结果完全没有实际意义，因为它 没有进行真正的分类或聚类 —— 所有样本都被认为是一个类，信息熵极低（接近0）。
**作用**：惩罚“类别分布过于集中”的情况，从而防止模型陷入把所有样本分为一个类的退化解。它鼓励更**均匀**的预测，使得聚类或自监督学习更有意义。
**举例**：假设有 3 个类别，模型对所有样本都输出 [0.99, 0.005, 0.005]，这看起来模型很“自信”，但实际只是懒惰地把所有东西归类为类别1。
      - 没有熵正则时：交叉熵损失可能很小 → 模型满意了。
      - 加上熵正则项后：因为这种预测分布熵太低 → 正则项会强制提高熵 → 模型被迫“分散”预测。

1.    Hungarian Algorithm（匈牙利算法）
**任务背景**：**分配问题**—— n 个工人和 n 项任务，为每个工人分配一项任务，使总成本最小（或总得分最大）
作用：在一个 n × n 的得分/代价矩阵中，找出一个一对一匹配，使得总分最高或总代价最低。
**举例**：在OW-Match论文中用于匹配聚类中心和类别参数：K 个聚类中心和K 个分类器权重向量
(1) 计算相似度矩阵 M: 计算所有聚类中心和所有权重之间的点积相似度,表示第i个聚类中心与第j个权重向量之间的相似度。
(2) 使用匈牙利算法获得最优匹配：从每一行选一个数（即为每个聚类中心分配一个权重向量），且每列最多选一次，使得选中的这些数加起来最大

1.   在向量的标准表示中，我们通常将向量表示为列向量
2.   确定研究方向：开放世界图学习————Open World Graph Learning; 异常检测——anomaly detection
3.   Sinkhorn-Knopp algorithm:用于生成增强图像的软伪标签(概率分布)

4. 成对相似性损失增强了类的可区分性。交叉熵损失有助于使用真标签和生成的伪标签对已知和新类别进行分类。熵正则化防止模型停留在过于简单的解决方案。防止单个类别主导批次。
5. 反事实本质上与因果推理的逻辑是一致的，因为它们回答了这样一个问题：为了使结果不同，输入需要发生什么变化？
6. 互信息（Mutual Information, MI）：衡量两个变量之间共享的信息量。如果一个变量的知识对另一个变量的知识没有帮助，那么MI为零；如果一个变量完全由另一个变量决定，那么MI为最大值。
- 归一化（Normalized）：将MI的值归一化到 [0, 1] 的范围内，方便比较。NMI = 1 表示两个聚类结果完全一致，NMI = 0 表示完全不相关。
- unseen_nmi 衡量的是模型对从未见过的类别进行聚类时，其聚类结果与真实标签有多么吻合。这个指标常用于开放集识别（Open-Set Recognition）或无监督表示学习（Unsupervised Representation Learning）等任务中，以检验模型是否能够很好地泛化到新类别。

